# Анализ облака точек с использованием СУБД

# Описание задания

## Тестовые данные

[Дан тестовый файл в виде облака точек (input)](https://drive.google.com/file/d/16qU5qoqaIvvhfJ3kG1wrspyfla-289zo/view?usp=sharing)

Текстовый Файл хранит координаты и цвета точек.

[Файл на Sketchfab](https://skfb.ly/6T7Yr)

[Оригинал](https://openheritage3d.org/project.php?id=708h-ss96)

## Основные этапы

### Постановка задачи

В рамках тестового задания необходимо придумать способ разбиения облака точек `input` на локальные области. Каждая локальная область должна содержать точки, которые геометрически расположены рядом друг с другом. Точность и мелкость разбиения может регулироваться параметрами.

После разбиения файла на локальные участки необходимо добавить их в СУБД PostGIS. 

В конце необходимо написать запрос, который выберет все точки в рамках заданного радиуса вокруг точки, которая является "центром масс" и отобразит их в виде [облака точек с цветом](https://plotly.com/python/3d-scatter-plots/). После получения результирующего набора также необходимо удалить дубликаты точек с заданной точность, которая является параметром запроса.

### Основные шаги

1. Запустить СУБД PostGIST (файл `docker-compose.yaml`).
2. Придумать способ разбиения облака точек `input` на локальные участки.
3. Написать ORM схему хранения данных в СУБД. При написании ORM необходимо учесть ограничения на хранение только разрешённых геометрических типов, которы были выбраны. Вставить другой геометрический тип должно быть нельзя.
4. Написать скрипт для добавления всех данных в СУБД.
5. Написать код, который выполняет запрос и отображает данные (jupyter notebook или скрипт на Python).
6. За какое время выполняется запрос при достаточно большом радиусе. Как можно ускорить выполнение запроса? Какое время запроса после того как был реализован предложенный способ ускорения. Постройте графики в зависимости от радиуса (вертикальная ось время, горизонтальная ось радиус).

### Примечания

Во время разбиения данных необходимо сэмулировать чтение по частям, по N-точек за раз. Технически можно загрузить все данные в оперативную память, но алгоритм должен работать только с подмножеством данных, а не со всем набором сразу. Любые операции в оперативной памяти над всем набором данных сразу не разрешены. В реальности не всегда можно сохранить все данные в оперативную память.  

Для запуска СУБД вам необходим Docker 19.04 или выше, а также [docker compose v2](https://github.com/docker/compose).

Все основные настройки заданы в `docker-compose.yaml` такие как логин, пароль, порт для подключения. Если при запуске выбранный порт занят, то можно его изменить на свободный.

Для упрощения процесса установки зависимостей (особенно под Windows) рекомендуется использовать [Anaconda](https://www.anaconda.com/products/distribution)

Если установка требует определённой ОС, то об этом нужно написать.

Для работу с СУБД и тестирования запросов можно использовать [DBeaver](https://dbeaver.io/)

# Основные критерии оценки выполнения задания

1. Код написан в едином стиле.
2. Файл с зависимостями не включает в себя специфичные для платформы или ОС пакеты, которые могут автоматически устанавливать как доп. зависимости (в основном актуально для Anaconda при стандартном экспорте файла с зависимостями). Это не включает в себя пакеты для которых нет собранной версии под определённую платформу.
2. Соблюдены основные соглашения PEP 8 для Python.
3. Как организована структура проекта.

# Полезные материалы для выполнения задания

1. [PostGIS](https://postgis.net/)
2. [ORM](https://www.sqlalchemy.org/)
3. [GEO ORM](https://github.com/geoalchemy/geoalchemy2)
4. [Shapely](https://github.com/shapely/shapely)
5. [docker compose v2](https://github.com/docker/compose)
6. [Docker](https://www.docker.com/)
